import triangleVertex from "./shaders/videoTexture.vert.wgsl?raw";
import triangleFrag from "./shaders/videoTexture.frag.wgsl?raw";
import { vertex, vertexCount } from './util/cubeWithUV';
import { mat4, vec3} from 'gl-matrix';
import videoUrl from '/video.mp4';

interface ModelView{
	x:number,
	y:number,
	z:number
}

const video = document.createElement('video');
video.loop = true;
video.autoplay = true;
video.muted = true;
video.src = videoUrl;
await video.play();

async function initWebGPU1(canvas:HTMLCanvasElement) {
	if (!navigator.gpu) throw new Error();
	const adapter = await navigator.gpu.requestAdapter({
		powerPreference: "high-performance", // è®¾ç½®gpuæ˜¯è¿è¡Œåœ¨é«˜ç”µé‡æ¨¡å¼è¿˜æ˜¯ä½Žç”µé‡æ¨¡å¼  æœŸæœ›é€‰é¡¹  å…·ä½“è¿˜è¦çœ‹æµè§ˆå™¨çš„å…·ä½“å®žé™…æ“ä½œ
	}); // ç›¸å½“äºŽæµè§ˆå™¨å¯¹webGPUçš„ä¸€ç§å…·ä½“çš„å®žçŽ°æŠ½è±¡ï¼Œå¯ä»¥è¯»å–å½“å‰æµè§ˆå™¨å¯¹webGPUå®žçŽ°äº†å“ªäº›åŠŸèƒ½å’Œå‚æ•°ï¼Œä¸èƒ½ç›´æŽ¥ç”¨å®ƒæ¥ç»˜åˆ¶å’Œè®¡ç®—å›¾å½¢
	adapter?.features.forEach((v) => {
		console.log("v", v); // æµè§ˆå™¨å¯¹webGPUçš„ä¸€äº›æ‰©å±•åŠŸèƒ½
	});
	if (!adapter) throw new Error();
	const device = await adapter.requestDevice({
		requiredFeatures: ["texture-compression-bc"], // èŽ·å–adapteré‡ç‚¹é¢ä¸€äº›æ‰©å±•åŠŸèƒ½å’Œå‚æ•°
		requiredLimits: {
			maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,
		},
	}); // webGPUåœ¨æµè§ˆå™¨çš„é€»è¾‘å¯¹è±¡ ç”¨äºŽç»˜å›¾

	const context = canvas.getContext("webgpu");
	if (!context) throw new Error();
	// const format = context.getPreferredFormat(adapter);
	const format = navigator.gpu.getPreferredCanvasFormat();

	canvas.width = canvas.clientWidth * window.devicePixelRatio;
	canvas.height = canvas.clientHeight * window.devicePixelRatio;
	const size = {
		width:canvas.width,
		height:canvas.height,
	};
	context.configure({
		device,
		format,
		//prevent chrome warning after v102
		alphaMode:'opaque'
		// size,
	});
	return { adapter, device, format, context,size };
}

async function initPipeline(device: GPUDevice, format: GPUTextureFormat,size:{width:number,height:number}) {
  console.log("ðŸš€ ~ file: rotatingCube.ts ~ line 41 ~ initPipeline ~ size", size)
	// const vertex = new Float32Array([
	// 	0,0.5,0,
	// 	-0.5,-0.5,0,
	// 	0.5,-0.5,0
	// ]);
	const vertexBuffer = device.createBuffer({
		size:vertex.byteLength,
		usage:GPUBufferUsage.VERTEX|GPUBufferUsage.COPY_DST
	});
	device.queue.writeBuffer(vertexBuffer,0,vertex); // GPUBUffer ,offset ,typedArray
	const color = new Float32Array([1,1,0,1]);
	const colorBuffer = device.createBuffer({
		size:color.byteLength,
		usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST
	});
	const mvpMatrixBuffer = device.createBuffer({
		size:4*4*4,
		usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST
	});


	device.queue.writeBuffer(colorBuffer,0,color);
	const vertexShader = device.createShaderModule({
		code: triangleVertex,
	});
	const fragShader = device.createShaderModule({
		code: triangleFrag,
	});
	const vertexObj = {
		vertex,vertexBuffer,vertexCount
	}
	const pipeline = await device.createRenderPipelineAsync({
		layout:'auto',
		// è¿™é‡Œæ•´ä½“æ ‡è¯†ä¼ å…¥çš„vertex bufferæ˜¯ä»¥æ¯12ä¸ªå­—èŠ‚åˆ’åˆ†ä¸ºä¸€ä¸ªå®šç‚¹æ•°æ®ä¼ å…¥shaderï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸­ä»Ž0ï¼ˆshaderLocationï¼‰å¼€å§‹
		// 3ä¸ªflaot32çš„æ•°å­—ä½œä¸ºä¸€ä¸ªå‚æ•°ä¼ å…¥shader@location(0)è¿™ä¸ªä½ç½®
		vertex: {
			module: vertexShader,
			entryPoint: "main",
			buffers:[{
				arrayStride: 5*4, //æ¯ä¸ªå®šç‚¹å ç”¨çš„ç©ºé—´å¤§å°
				attributes:[
					{
						shaderLocation:0,
						offset:0,
						format:'float32x3'  //æ ‡è¯†å‚æ•°çš„é•¿åº¦å¤§å°
					},
					{
						shaderLocation:1,
						offset:3*4,
						format:'float32x2'  //æ ‡è¯†å‚æ•°çš„é•¿åº¦å¤§å°
					},
				] // åˆ‡åˆ†å‡ºæ¥çš„arrayå¦‚ä½•å¯¹åº”shaderé‡Œçš„å‚æ•°
			}] // æ ‡è¯†pipelineå¯ä»¥ä¼ å…¥å‡ ä¸ªå®šç‚¹æ•°æ®  ç›®å‰æ”¯æŒä¸€ä¸ªpipelineæœ€å¤šä¼ å…¥8ä¸ªå®šç‚¹æ•°æ®
		},
		fragment: {
			module: fragShader,
			entryPoint: "main", // å…¥å£å‡½æ•°
			targets: [
				{
					format, //å‘Šè¯‰webgpushaderä½¿ç”¨çš„æ˜¯å“ªç§é¢œè‰²æ ¼å¼
				},
			],
		},
		primitive:{
			// point-list æ¯ä¸€ä¸ªç‚¹éƒ½å•åšç‹¬ç«‹çš„ç‚¹è¾“å‡º
			// line-list æ¯ä¸¤ä¸ªç‚¹ç»„æˆä¸€æ¡çº¿è¾“å‡º
			// line-strip 12 23 34çš„ç»„åˆæ–¹å¼è¾“å‡ºçº¿
			// triangle-strip å…±ç”¨å®šç‚¹è¾“å‡ºä¸‰è§’å½¢ 4ä¸ªå®šç‚¹ç»„æˆä¸€ä¸ªæ­£æ–¹å½¢
			// trangle-list ä¸å…±ç”¨å®šç‚¹è¾“å‡ºä¸‰è§’å½¢ 6ä¸ªå®šç‚¹ç»„æˆä¸€ä¸ªæ­£æ–¹å½¢
			topology:'triangle-list',
			cullMode:'back',//é¢å‰”é™¤,
			frontFace: 'ccw'
		},
		depthStencil:{
			depthWriteEnabled:true,
			depthCompare:'less',
			format:'depth24plus'// æ·±åº¦å­˜å‚¨çš„ç²¾åº¦ 24ä½æ·±åº¦è´´å›¾  æ·±åº¦è´´å›¾çš„æ•°æ®æ ¼å¼
		},
	});

	const depthTexture = device.createTexture({
		size,format:'depth24plus',usage:GPUTextureUsage.RENDER_ATTACHMENT
	})

	// webgpuä¸­æœ€å¤šä¸€ä¸ªgroupæœ€å¤šç»‘å®š8ä¸ªèµ„æº
	const group = device.createBindGroup({
		layout:pipeline.getBindGroupLayout(0),
		entries:[
		// 	{
		// 	binding:0,
		// 	resource:{
		// 		buffer:colorBuffer
		// 	}
		// },
		{
			binding:0,
			resource:{
				buffer:mvpMatrixBuffer
			}
		}
	]
	});
	const colorObj = {
		color,colorBuffer,group
	}
	return {pipeline,vertexObj,colorObj,mvpMatrixBuffer,depthTexture}
}

function getMvpMatrix(size:{width:number,height:number},position:ModelView,rotation:ModelView,scale:ModelView){
	// const position = {x:0,y:0,z:-8};
	// const rotation = {x:0.5,y:0,z:0};
	// const scale = {x:1,y:1,z:1};

	const modelViewMatrix = mat4.create();
	mat4.translate(modelViewMatrix, modelViewMatrix,vec3.fromValues(position.x,position.y,position.z));

	mat4.rotateX(modelViewMatrix,modelViewMatrix,rotation.x);
	mat4.rotateY(modelViewMatrix,modelViewMatrix,rotation.y);
	mat4.rotateZ(modelViewMatrix,modelViewMatrix,rotation.z);
	
	mat4.scale(modelViewMatrix,modelViewMatrix,vec3.fromValues(scale.x,scale.y,scale.z));
	
	const projectionMatrix = mat4.create();
	mat4.perspective(projectionMatrix, Math.PI/4, size.width/size.height,0.1,100);
	const mvpMatrix = mat4.create();
	mat4.multiply(mvpMatrix, projectionMatrix, modelViewMatrix);
	return mvpMatrix;
}

function draw(device:GPUDevice,pipeline:GPURenderPipeline,context:GPUCanvasContext,vertexObj:any,colorObj:any,depthTexture:GPUTexture,textureGroup:GPUBindGroup){
	const encoder = device.createCommandEncoder();// æ‰€æœ‰çš„å‘½ä»¤éƒ½æå‰å†™å…¥encoderä¸­ï¼Œç„¶åŽå†ä¸€æ¬¡æ€§æäº¤nativeè¿è¡Œ
	const renderPass = encoder.beginRenderPass({ // è¿™ä¸ªpassæœ€ç»ˆçš„ç»“æžœä¼šå¯¹åº”åˆ°ç›¸åº”çš„canvasä¸Š
		colorAttachments:[{
			view: context.getCurrentTexture().createView(),//é€šé“è¾“å‡ºåœ¨å“ªé‡Œæ˜¾ç¤º  èŽ·å–ä¸€ä¸ªå¯ä»¥è¢«GPUæ“ä½œçš„view buffer
			loadOp:'clear',// ç»˜åˆ¶å‰æ˜¯å¦åŠ è½½å½“å‰viewçš„å†…å®¹  clearæ¸…ç©º  loadæ˜¯åœ¨åŽŸæœ‰çš„å†…å®¹çš„åŸºç¡€ä¸Šæ·»åŠ æ–°çš„å†…å®¹
			clearValue:{r:0,g:0,b:0,a:1}, //èƒŒæ™¯è‰²
			storeOp:'store'// ç»˜åˆ¶åŽå¯¹viewè¿›è¡Œä»€ä¹ˆæ“ä½œ  storeä¿ç•™  discardä¸¢å¼ƒç»“æžœ
	}],
	depthStencilAttachment:{
		view:depthTexture.createView(),
		depthLoadOp:'clear',
		depthClearValue:1.0, //zå–å€¼èŒƒå›´æ˜¯0-1.0
		depthStoreOp:'store'// æœ€åŽçš„ç»“æžœæ˜¯å¦è¦ä¿ç•™
	}
	});
	renderPass.setPipeline(pipeline);
	renderPass.setVertexBuffer(0,vertexObj.vertexBuffer);
	renderPass.setBindGroup(0,colorObj.group);
	renderPass.setBindGroup(1,textureGroup);
	renderPass.draw(vertexObj.vertexCount); //å®šç‚¹ä¸ªæ•° vertexShaderä¼šè¢«å¹¶è¡Œæ‰§è¡Œä¸‰æ¬¡
	renderPass.end();
	const buffer = encoder.finish();
	device.queue.submit([buffer]);// è¿™æ—¶GPUæ‰å¼€å§‹å·¥ä½œ
}

async function run() {
	const canvas = document.querySelector('canvas')
	if (!canvas)
			throw new Error('No Canvas')
	const { device, format, context, size } = await initWebGPU1(canvas);
	const {pipeline, vertexObj, colorObj,mvpMatrixBuffer,depthTexture} = await initPipeline(device, format,size);

	// device.queue.copyExternalImageToTexture({source:bitmap},{texture},textureSize);
	const sampler = device.createSampler({
		magFilter:'linear',
		minFilter:'linear',
	});

	const position = {x:0,y:0,z:-8};
	const rotation = {x:0.5,y:0,z:0};
	const scale = {x:1,y:1,z:1};
	// const mvpMatrix = getMvpMatrix(size,position,rotation,scale);
	// device.queue.writeBuffer(mvpMatrixBuffer,0, mvpMatrix as Float32Array);
	// draw(device,pipeline,context,vertexObj, colorObj,depthTexture,videoGroup);

	function animation(){
		const now = Date.now()/1000;
		rotation.x = Math.sin(now)
		rotation.y = Math.cos(now)
		const mvpMatrix = getMvpMatrix(size,position,rotation,scale);

		        // video frame rate may not different with page render rate
        // we can use VideoFrame to force video decoding current frame
        const videoFrame = new VideoFrame(video)
        // it can be imported to webgpu as texture source with the `webgpu-developer-features` flag enabled
        // const texture = device.importExternalTexture({
        //     source: videoFrame // need `webgpu-developer-features`
        // })
        // but in this demo, we don't acctully use it, just close it
        videoFrame.close()
		const texture = device.importExternalTexture({
			source:video
		});
		const videoGroup = device.createBindGroup({
			label:'Texture Group with Texture/Sampler',
			layout:pipeline.getBindGroupLayout(1),
			entries:[{
				binding:0,
				resource:sampler
			},{
				binding:1,
				resource:texture
			}]
		})
		device.queue.writeBuffer(mvpMatrixBuffer,0,mvpMatrix as Float32Array);
		draw(device,pipeline,context,vertexObj, colorObj,depthTexture,videoGroup);
		requestAnimationFrame(animation);
	}
	animation();
// 	document.querySelector('input[type="color"]')?.addEventListener('input', (e:Event) => {
// 		// get hex color string
// 		const color = (e.target as HTMLInputElement).value
// 		console.log(color)
// 		// parse hex color into rgb
// 		const r = +('0x' + color.slice(1, 3)) / 255
// 		const g = +('0x' + color.slice(3, 5)) / 255
// 		const b = +('0x' + color.slice(5, 7)) / 255
// 		// write colorBuffer with new color
// 		device.queue.writeBuffer(colorObj.colorBuffer, 0, new Float32Array([r, g, b, 1]))
// 		draw(device,pipeline, context,vertexObj, colorObj,depthTexture);
// })
// document.querySelector('input[type="range"]')?.addEventListener('input', (e:Event) => {
// 	// get input value
// 	const value = +(e.target as HTMLInputElement).value
// 	console.log(value)
// 	// chagne vertex 0/3/6
// 	vertexObj.vertex[0] = 0 + value
// 	vertexObj.vertex[3] = -0.5 + value
// 	vertexObj.vertex[6] = 0.5 + value
// 	// write vertexBuffer with new vertex
// 	device.queue.writeBuffer(vertexObj.vertexBuffer, 0, vertexObj.vertex)
// 	draw(device,pipeline, context,vertexObj, colorObj,depthTexture);
// });
window.addEventListener('resize',()=>{
	size.width = canvas.width = canvas.clientWidth * window.devicePixelRatio;
	size.height = canvas.height = canvas.clientHeight * window.devicePixelRatio;
	console.log('size',size);
	depthTexture.destroy();
	const newDepthTexture = device.createTexture({
		size,format:'depth24plus',usage:GPUTextureUsage.RENDER_ATTACHMENT
	});
	draw(device,pipeline, context,vertexObj, colorObj,newDepthTexture,videoGroup);
})
}


run();
